import numpy as np
import torch
import torch.nn.functional as F
from PIL import Image
from torchvision.transforms.functional import resize, pad, center_crop, to_tensor, to_pil_image, crop
from torchvision.transforms import InterpolationMode
from math import ceil, sqrt
import matplotlib.pyplot as plt

####################################################################################################################################################
####################################################################################################################################################
####################################################################################################################################################
####################################################################################################################################################
############################################################ Shift-Invariant Model Utils ###########################################################
####################################################################################################################################################
####################################################################################################################################################
####################################################################################################################################################
####################################################################################################################################################
def shift_invariant_model(x, k):
    """
    Inputs:
        x: Image tensor of shape (1, C, H, W)
        k: PSF tensor of shape (1, C, H, W)
    """
    if x.shape[-2:] != k.shape[-2:]:
        x = pad(x, ((k.shape[-2]-x.shape[-2])//2, (k.shape[-1]-x.shape[-1])//2))
    x_p = pad(x, (x.shape[-2]//2, x.shape[-1]//2))
    k_p = pad(k, (k.shape[-2]//2, k.shape[-1]//2))
    x_f = torch.fft.fft2(torch.fft.fftshift(x_p, dim=(-2,-1)))
    k_f = torch.fft.fft2(torch.fft.fftshift(k_p, dim=(-2,-1)))
    y_f = x_f * k_f
    y = torch.fft.ifftshift(torch.fft.ifft2(y_f), dim=(-2,-1))
    y = center_crop(y, (x.shape[-2], x.shape[-1]))
    return torch.real(y)

####################################################################################################################################################
####################################################################################################################################################
####################################################################################################################################################
####################################################################################################################################################
############################################################# Shift-Variant Model Utils ############################################################
####################################################################################################################################################
####################################################################################################################################################
####################################################################################################################################################
####################################################################################################################################################
def shift_variant_model_optimized(x, k):
    """
    Efficient version of shift_variant_model.

    Inputs:
        x: Tensor of shape (B, C, H, W)
        k: Tensor of shape (B, C, 2H, 2W)
    Returns:
        meas: Tensor of shape (B, C, H, W)
    """
    B, C, H, W = x.shape
    x_flipped = torch.flip(x, (-2, -1))  # Flip spatial dimensions

    # Create sliding patches of size (H, W) from each (2H, 2W) PSF
    k_patches = F.unfold(k, kernel_size=(H, W))  # shape: (B*C, H*W, H*W)
    k_patches = k_patches.transpose(1, 2).view(B, C, H, W, H, W)

    # Compute element-wise multiplication and sum over the last two dims
    meas = (x_flipped.unsqueeze(-2).unsqueeze(-2) * k_patches).sum(dim=(-1, -2))

    return meas


def shift_variant_model_memory_efficient(x, k):
    """
    Memory-efficient version of shift_variant_model.

    Inputs:
        x: Tensor of shape (B, C, H, W)
        k: Tensor of shape (B, C, 2H, 2W)
    Returns:
        meas: Tensor of shape (B, C, H, W)
    """
    B, C, H, W = x.shape
    x_flipped = torch.flip(x, (-2, -1))
    meas = torch.zeros_like(x)

    for i in range(H):
        for j in range(W):
            # Crop (H, W) patch from each PSF at position (i, j)
            cropped_k = k[..., i:i + H, j:j + W]  # Shape: (B, C, H, W)
            meas[..., i, j] = (x_flipped * cropped_k).sum(dim=(-1, -2))

    return meas

def shift_variant_model(x, k):
    """
    Inputs:
        x: Image tensor of shape (B, C, H, W)
        k: PSF tensor of shape (B, C, 2H, 2W)
    """
    x = torch.flip(x, (-2, -1))
    meas = torch.zeros_like(x)
    for i in range(x.shape[-2]):
        for j in range(x.shape[-1]):
            meas[..., i, j] = (x * crop(k, top=i, left=j, height=x.shape[-2], width=x.shape[-1])).sum(dim=(-1, -2))

    return meas

####################################################################################################################################################
####################################################################################################################################################
####################################################################################################################################################
####################################################################################################################################################
############################################################## Local Convolution Utils #############################################################
####################################################################################################################################################
####################################################################################################################################################
####################################################################################################################################################
####################################################################################################################################################

def weighted_local_convolution(x, k, w):
    """
    Local convolution in the frequency domain with weighted merging
    Implementation inspired by phocolens paper

    Input:
        x: Input image to be convolved (1, C, H_x, W_x)
        k: PSF stack (K, 1, H_k, W_k)
        m: Weights for the weighted average summing 1 along dimension K (K, 1, H, W)
    Output:
        y: Locally convolved measurement (1, C, H_x, W_x)
    """
    # Convert to frequency domain
    x = x.repeat(k.shape[0], 1, 1, 1)
    x *= w
    x_p = pad(x, ((k.shape[-2]-x.shape[-2])//2, (k.shape[-1]-x.shape[-1])//2))
    y_p = shift_invariant_model(x_p, k)
    # Perform weighted average
    y = (y_p).sum(dim=0).unsqueeze(0)

    return y